# ğŸ¤– ML API - ConfiguraÃ§Ã£o e Deploy

Este documento explica como configurar e fazer deploy da API de Machine Learning para previsÃµes financeiras.

## ğŸ“‹ PrÃ©-requisitos

- Python 3.10+
- MongoDB (local ou Atlas)
- Conta no Render.com (para deploy)

## ğŸš€ Setup Local

### 1. Instalar DependÃªncias

```bash
cd ml-api
pip install -r requirements.txt
```

### 2. Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` na pasta `ml-api`:

```env
MONGODB_URI=mongodb://localhost:27017/savemymoney
API_PORT=8000
NODE_API_URL=http://localhost:5000
SECRET_KEY=your-secret-key-change-this
```

### 3. Iniciar o Servidor

```bash
# OpÃ§Ã£o 1: Usando uvicorn diretamente
python -m uvicorn app.main:app --reload --port 8000

# OpÃ§Ã£o 2: Usando o script main.py
python app/main.py
```

A API estarÃ¡ disponÃ­vel em: `http://localhost:8000`

### 4. Testar a API

```bash
# Health check
curl http://localhost:8000/health

# Resposta esperada:
# {"status":"healthy","service":"ml-api"}
```

## ğŸŒ Deploy no Render.com

### Passo 1: Criar Web Service

1. Acesse [Render.com Dashboard](https://dashboard.render.com/)
2. Clique em **"New +"** â†’ **"Web Service"**
3. Conecte seu repositÃ³rio GitHub
4. Configure:
   - **Name**: `savemymoney-ml-api`
   - **Region**: `Oregon (US West)` (ou mais prÃ³ximo)
   - **Branch**: `main`
   - **Root Directory**: `ml-api`
   - **Runtime**: `Python 3`
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`

### Passo 2: Configurar VariÃ¡veis de Ambiente

No painel do Render, adicione as seguintes variÃ¡veis:

| Key | Value | DescriÃ§Ã£o |
|-----|-------|-----------|
| `MONGODB_URI` | `mongodb+srv://user:pass@cluster.mongodb.net/savemymoney` | MongoDB Atlas connection string |
| `API_PORT` | `8000` | Porta da API |
| `NODE_API_URL` | `https://savemymoney-backend.onrender.com` | URL do backend Node.js |
| `SECRET_KEY` | `[gere uma senha forte]` | Chave secreta para JWT |
| `PYTHON_VERSION` | `3.11.0` | VersÃ£o do Python |

### Passo 3: Atualizar Backend para Usar ML API

No backend Node.js (Render), adicione a variÃ¡vel:

```env
ML_API_URL=https://savemymoney-ml-api.onrender.com
```

### Passo 4: Deploy

1. Clique em **"Create Web Service"**
2. Aguarde o deploy (3-5 minutos)
3. Teste a URL: `https://savemymoney-ml-api.onrender.com/health`

## ğŸ“Š Endpoints DisponÃ­veis

### Health Check
```http
GET /health
```

**Resposta:**
```json
{
  "status": "healthy",
  "service": "ml-api"
}
```

### Fazer PrevisÃ£o
```http
POST /api/predictions/predict
Content-Type: application/json
Authorization: Bearer {token}

{
  "user_id": "user123",
  "category": "AlimentaÃ§Ã£o",
  "days_ahead": 30,
  "model_type": "linear"
}
```

**Resposta:**
```json
{
  "predictions": [12.5, 15.3, 18.2, ...],
  "dates": ["2025-01-01", "2025-01-02", ...],
  "confidence_interval": {
    "lower": [10.0, 12.0, ...],
    "upper": [15.0, 18.0, ...]
  },
  "model_type": "linear",
  "accuracy_score": 0.85
}
```

### Obter Insights
```http
GET /api/predictions/insights/{user_id}
Authorization: Bearer {token}
```

### PrevisÃ£o por Categoria
```http
GET /api/predictions/category/{user_id}/{category}?days_ahead=30
Authorization: Bearer {token}
```

### Comparar PrevisÃµes
```http
GET /api/predictions/compare/{user_id}
Authorization: Bearer {token}
```

## ğŸ”§ Modelos de ML DisponÃ­veis

### 1. RegressÃ£o Linear (`linear`)
- **Uso**: TendÃªncias lineares simples
- **Vantagens**: RÃ¡pido, leve, interpretÃ¡vel
- **Melhor para**: Dados com padrÃµes lineares claros
- **PrecisÃ£o**: 70-80%

### 2. LSTM (`lstm`)
- **Uso**: PadrÃµes complexos e sazonalidade
- **Vantagens**: Alta precisÃ£o, captura dependÃªncias temporais
- **Melhor para**: Dados histÃ³ricos extensos (>100 registros)
- **PrecisÃ£o**: 80-90%
- **Nota**: Requer mais memÃ³ria e tempo de processamento

## ğŸ› Troubleshooting

### Erro: "API ML: Desconectada"

**Causa**: ML API nÃ£o estÃ¡ rodando ou URL incorreta

**SoluÃ§Ã£o**:
1. Verifique se a ML API estÃ¡ rodando: `curl http://localhost:8000/health`
2. Confirme a variÃ¡vel `ML_API_URL` no backend
3. Verifique logs do Render para erros

### Erro: "Connection refused"

**Causa**: MongoDB nÃ£o estÃ¡ acessÃ­vel

**SoluÃ§Ã£o**:
1. Verifique o `MONGODB_URI` no .env
2. Confirme que o MongoDB Atlas permite conexÃµes do IP do Render
3. Teste a conexÃ£o com: `mongosh "mongodb+srv://..."`

### Erro: "Module not found"

**Causa**: DependÃªncias nÃ£o instaladas

**SoluÃ§Ã£o**:
```bash
cd ml-api
pip install -r requirements.txt --force-reinstall
```

### Deploy falha no Render

**Causa**: ConfiguraÃ§Ã£o incorreta

**SoluÃ§Ã£o**:
1. Confirme que o `Root Directory` Ã© `ml-api`
2. Verifique o Start Command: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`
3. Confirme que `requirements.txt` existe em `ml-api/`
4. Verifique logs de build no Render

## ğŸ§ª Testando Localmente

### 1. Com dados reais

```python
import requests

# Health check
response = requests.get("http://localhost:8000/health")
print(response.json())

# Fazer previsÃ£o
payload = {
    "user_id": "user123",
    "category": "AlimentaÃ§Ã£o",
    "days_ahead": 7,
    "model_type": "linear"
}

headers = {"Authorization": "Bearer YOUR_JWT_TOKEN"}

response = requests.post(
    "http://localhost:8000/api/predictions/predict",
    json=payload,
    headers=headers
)

print(response.json())
```

### 2. Com curl

```bash
# Health check
curl http://localhost:8000/health

# PrevisÃ£o
curl -X POST http://localhost:8000/api/predictions/predict \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "user_id": "user123",
    "category": "AlimentaÃ§Ã£o",
    "days_ahead": 30,
    "model_type": "linear"
  }'
```

## ğŸ“¦ Estrutura do Projeto

```
ml-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ database.py          # MongoDB connection
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ linear_predictor.py   # RegressÃ£o Linear
â”‚   â”‚   â””â”€â”€ lstm_predictor.py     # LSTM
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py       # Pydantic models
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ predictions.py   # Endpoints
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ .env                     # VariÃ¡veis de ambiente (nÃ£o commitado)
â””â”€â”€ README.md
```

## ğŸ” SeguranÃ§a

### ProduÃ§Ã£o

1. **Use HTTPS**: Configure certificado SSL no Render
2. **Restrinja CORS**: Remova `"*"` e liste apenas origens especÃ­ficas
3. **JWT Validation**: Valide tokens do backend Node.js
4. **Rate Limiting**: Implemente limitaÃ§Ã£o de requisiÃ§Ãµes
5. **Secrets**: Use variÃ¡veis de ambiente do Render (nunca commite .env)

### Exemplo de CORS restrito:

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://savemymoney-frontend.onrender.com",
        "https://savemymoney-backend.onrender.com"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["Authorization", "Content-Type"],
)
```

## ğŸ“ˆ Performance

### OtimizaÃ§Ãµes

1. **Cache de Modelos**: Modelos treinados sÃ£o salvos em memÃ³ria
2. **Connection Pooling**: MongoDB usa pool de conexÃµes
3. **Async Operations**: FastAPI Ã© totalmente assÃ­ncrono
4. **Lazy Loading**: Modelos sÃ£o carregados sob demanda

### Limites Render Free Tier

- **MemÃ³ria**: 512 MB
- **CPU**: Compartilhado
- **Sleep**: ApÃ³s 15 min de inatividade
- **Bandwidth**: 100 GB/mÃªs

**Dica**: Use um cron job para manter a API ativa:
```bash
# No crontab ou serviÃ§o externo
*/10 * * * * curl https://savemymoney-ml-api.onrender.com/health
```

## ğŸ“š Recursos Adicionais

- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [TensorFlow/Keras Guide](https://www.tensorflow.org/guide/keras)
- [scikit-learn](https://scikit-learn.org/stable/)
- [Render Python Docs](https://render.com/docs/deploy-fastapi)

## ğŸ†˜ Suporte

Se encontrar problemas:

1. Verifique os logs: `Render Dashboard â†’ Logs`
2. Teste localmente primeiro
3. Confirme variÃ¡veis de ambiente
4. Verifique conectividade com MongoDB

---

**Status**: âœ… Pronto para deploy
**Ãšltima atualizaÃ§Ã£o**: 2025-01-17
